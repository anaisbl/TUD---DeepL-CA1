{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Image Processing & Transfer learning\n",
    "This notebook contains code to import and split the CIFAR-100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar100\n",
    "import os\n",
    "\n",
    "# load CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "\n",
    "# randomly select 50-50 classes for Block 1 & Block 2\n",
    "all_classes = np.unique(y_train)\n",
    "np.random.shuffle(all_classes)\n",
    "block1_classes = all_classes[:50]\n",
    "block2_classes = all_classes[50:100]\n",
    "\n",
    "# filter data for Block 1\n",
    "block1_train_indices = np.isin(y_train, block1_classes).flatten()\n",
    "x_block1_train = x_train[block1_train_indices]\n",
    "y_block1_train = y_train[block1_train_indices]\n",
    "\n",
    "# filter data for Block 2\n",
    "block2_train_indices = np.isin(y_train, block2_classes).flatten()\n",
    "x_block2_train = x_train[block2_train_indices]\n",
    "y_block2_train = y_train[block2_train_indices]\n",
    "\n",
    "# split data into train-validation for Block 1\n",
    "split_index = int(len(x_block1_train) * 0.8)\n",
    "x_block1_val = x_block1_train[split_index:]\n",
    "y_block1_val = y_block1_train[split_index:]\n",
    "x_block1_train = x_block1_train[:split_index]\n",
    "y_block1_train = y_block1_train[:split_index]\n",
    "\n",
    "# split data into train-validation for Block 2\n",
    "split_index = int(len(x_block2_train) * 0.8)\n",
    "x_block2_val = x_block2_train[split_index:]\n",
    "y_block2_val = y_block2_train[split_index:]\n",
    "x_block2_train = x_block2_train[:split_index]\n",
    "y_block2_train = y_block2_train[:split_index]\n",
    "\n",
    "# encode labels to range from 0 to 49 for both blocks\n",
    "y_block1_train_encoded = (y_block1_train - block1_classes.min()) % 50\n",
    "y_block1_val_encoded = (y_block1_val - block1_classes.min()) % 50\n",
    "y_block2_train_encoded = (y_block2_train - block2_classes.min()) % 50\n",
    "y_block2_val_encoded = (y_block2_val - block2_classes.min()) % 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if encoded labels within range\n",
    "print(np.min(y_block1_train_encoded), \"Max:\", np.max(y_block1_train_encoded))\n",
    "print(np.min(y_block1_val_encoded), \"Max:\", np.max(y_block1_val_encoded))\n",
    "print(np.min(y_block1_train_encoded), \"Max:\", np.max(y_block2_train_encoded))\n",
    "print(np.min(y_block1_val_encoded), \"Max:\", np.max(y_block2_val_encoded))\n",
    "\n",
    "# check shape of datasets\n",
    "print(\"Shape of x_block1_train:\", x_block1_train.shape)\n",
    "print(\"Shape of y_block1_train:\", y_block1_train.shape)\n",
    "print(\"Shape of x_block1_val:\", x_block1_val.shape)\n",
    "print(\"Shape of y_block1_val:\", y_block1_val.shape)\n",
    "\n",
    "print(\"Shape of x_block2_train:\", x_block2_train.shape)\n",
    "print(\"Shape of y_block2_train:\", y_block2_train.shape)\n",
    "print(\"Shape of x_block2_val:\", x_block2_val.shape)\n",
    "print(\"Shape of y_block2_val:\", y_block2_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directories to save subsets\n",
    "os.makedirs(\"p2_data/block1/train\", exist_ok=True)\n",
    "os.makedirs(\"p2_data/block1/val\", exist_ok=True)\n",
    "os.makedirs(\"p2_data/block2/train\", exist_ok=True)\n",
    "os.makedirs(\"p2_data/block2/val\", exist_ok=True)\n",
    "\n",
    "# save subsets\n",
    "np.save(\"p2_data/block1/train/x_train.npy\", x_block1_train)\n",
    "np.save(\"p2_data/block1/train/y_train.npy\", y_block1_train_encoded)\n",
    "np.save(\"p2_data/block1/val/x_val.npy\", x_block1_val)\n",
    "np.save(\"p2_data/block1/val/y_val.npy\", y_block1_val_encoded)\n",
    "\n",
    "np.save(\"p2_data/block2/train/x_train.npy\", x_block2_train)\n",
    "np.save(\"p2_data/block2/train/y_train.npy\", y_block2_train_encoded)\n",
    "np.save(\"p2_data/block2/val/x_val.npy\", x_block2_val)\n",
    "np.save(\"p2_data/block2/val/y_val.npy\", y_block2_val_encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

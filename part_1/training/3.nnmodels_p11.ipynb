{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2 - Neural Network Models\n",
    "This notebook contains all RNN models, variants and embeddings for Genre prediction using 2 input feature: song lyrics and artist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import random\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# import file\n",
    "music_df = pd.read_csv(\"p1_data/sample_train.csv\", index_col=False, sep=\",\", quotechar='\"')\n",
    "\n",
    "# function to lowercase, remove punctuation & stopwords\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return filtered_text\n",
    "\n",
    "# preprocess lyrics\n",
    "music_df[\"Prsd_Lyrics\"] = music_df[\"Lyrics\"].apply(preprocess_text)\n",
    "\n",
    "# preprocess artist\n",
    "music_df[\"Prsd_Artist\"] = music_df[\"Artist\"].apply(preprocess_text)\n",
    "\n",
    "# extract labels & convert to one-hot encoded vectors\n",
    "labels = music_df[\"Genre\"]\n",
    "label_dict = {label: i for i, label in enumerate(labels.unique())}\n",
    "labels_encoded = labels.map(label_dict)\n",
    "labels_categorical = tf.keras.utils.to_categorical(labels_encoded)\n",
    "\n",
    "# tokenize & pad lyrics and artist\n",
    "tokenizer_lyrics = Tokenizer(char_level=True)\n",
    "tokenizer_artist = Tokenizer()\n",
    "tokenizer_lyrics.fit_on_texts(music_df['Prsd_Lyrics'])\n",
    "sequences_lyrics = tokenizer_lyrics.texts_to_sequences(music_df['Prsd_Lyrics'])\n",
    "tokenizer_artist.fit_on_texts(music_df['Prsd_Artist'])\n",
    "sequences_artist = tokenizer_artist.texts_to_sequences(music_df['Prsd_Artist'])\n",
    "\n",
    "max_lyric_length = 4000 # chosen based on distribution above, excluding extreme values\n",
    "max_artist_length = 25 # chosen based on distribution above, excluding extreme values\n",
    "\n",
    "# combine input features\n",
    "X_lyrics = pad_sequences(sequences_lyrics, maxlen=max_lyric_length)\n",
    "X_artist = pad_sequences(sequences_artist, maxlen=max_artist_length)\n",
    "X = np.concatenate((X_lyrics, X_artist), axis=1)\n",
    "\n",
    "# randomly shuffle data indices of dataframe\n",
    "data_indices = list(range(len(music_df)))\n",
    "random.shuffle(data_indices)\n",
    "\n",
    "# split data into train/test using indices\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(music_df) * split_ratio)\n",
    "train_indices = data_indices[:split_index]\n",
    "test_indices = data_indices[split_index:]\n",
    "\n",
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_train = labels_categorical[train_indices]\n",
    "y_test = labels_categorical[test_indices]\n",
    "\n",
    "# reshape for RNN & CNN architecture compatibility\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Models\n",
    "Exploring Simple RNN, LSTM and dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# learning rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple rnn model\n",
    "rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=64, return_sequences=False),\n",
    "    tf.keras.layers.Dense(units=64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=len(label_dict), activation=\"softmax\") # final output layer\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "rnn_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "# train & evaluate the model\n",
    "rnn_model.fit(X_train, y_train, epochs=10, validation_split=0.2, callbacks=[early_stopping])\n",
    "rnn_loss, rnn_accuracy = rnn_model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", rnn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM rnn model\n",
    "lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=8, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(16),\n",
    "    tf.keras.layers.Dense(units=len(label_dict), activation=\"softmax\") # final output layer\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "lstm_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "# train & evaluate the model\n",
    "lstm_model.fit(X_train, y_train, epochs=10, validation_split=0.2, callbacks=[early_stopping])\n",
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", lstm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-model Embedding\n",
    "Variations of \"on-the-job\" embedding with different NN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine test/train data\n",
    "X_train_lyric = X_lyrics[train_indices]\n",
    "X_train_artist = X_artist[train_indices]\n",
    "y_train = labels_categorical[train_indices]\n",
    "\n",
    "X_test_lyric = X_lyrics[test_indices]\n",
    "X_test_artist = X_artist[test_indices]\n",
    "y_test = labels_categorical[test_indices]\n",
    "\n",
    "# define vocab size & embedding dimension\n",
    "embedding_dim = 100 \n",
    "artist_vocab_size = len(tokenizer_artist.word_index) + 1 # number of unique words\n",
    "lyric_vocab_size = len(tokenizer_lyrics.word_index) + 1 # number of unique words\n",
    "\n",
    "# define input layers\n",
    "lyric_input = tf.keras.layers.Input(shape=(max_lyric_length,))\n",
    "artist_input = tf.keras.layers.Input(shape=(max_artist_length,))\n",
    "\n",
    "# embedding layer\n",
    "lyric_embedding = tf.keras.layers.Embedding(input_dim=lyric_vocab_size, output_dim=embedding_dim, input_length=max_lyric_length)(lyric_input)\n",
    "lyric_flatten = tf.keras.layers.Flatten()(lyric_embedding)\n",
    "artist_embedding = tf.keras.layers.Embedding(input_dim=artist_vocab_size, output_dim=embedding_dim, input_length=max_artist_length)(artist_input)\n",
    "artist_flatten = tf.keras.layers.Flatten()(artist_embedding)\n",
    "concatenated = tf.keras.layers.concatenate([lyric_flatten, artist_flatten])\n",
    "\n",
    "# to reshape LSTM & RNN to 1 timestep\n",
    "reshaped = tf.keras.layers.Reshape((1, -1))(concatenated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM + Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM layer\n",
    "lstm_layer = tf.keras.layers.LSTM(units=64)(reshaped)\n",
    "\n",
    "# output layer\n",
    "output1 = tf.keras.layers.Dense(len(label_dict), activation='softmax')(lstm_layer)\n",
    "\n",
    "# define model\n",
    "emb_model1 = tf.keras.Model(inputs=[lyric_input, artist_input], outputs=output1)\n",
    "\n",
    "# compile , train & evaluate the model\n",
    "emb_model1.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "emb_model1.fit([X_train_lyric, X_train_artist], y_train, epochs=10, validation_split=0.2, callbacks=[early_stopping])\n",
    "emb_loss1, emb_accuracy1 = emb_model1.evaluate([X_test_lyric, X_test_artist], y_test)\n",
    "print(\"Test Accuracy:\", emb_accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN + Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple RNN layers\n",
    "rnn_layer1 = tf.keras.layers.SimpleRNN(units=64)(reshaped)\n",
    "\n",
    "# output layer\n",
    "output2 = tf.keras.layers.Dense(len(label_dict), activation='softmax')(rnn_layer1)\n",
    "\n",
    "# define model\n",
    "emb_model2 = tf.keras.Model(inputs=[lyric_input, artist_input], outputs=output2)\n",
    "\n",
    "# compile , train & evaluate the model\n",
    "emb_model2.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "emb_model2.fit([X_train_lyric, X_train_artist], y_train, epochs=10, validation_split=0.2, callbacks=[early_stopping])\n",
    "emb_loss2, emb_accuracy2 = emb_model2.evaluate([X_test_lyric, X_test_artist], y_test)\n",
    "print(\"Test Accuracy:\", emb_accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense + Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense layer\n",
    "dense1 = tf.keras.layers.Dense(units=64)(concatenated)\n",
    "\n",
    "# output layer\n",
    "output3 = tf.keras.layers.Dense(len(label_dict), activation='softmax')(dense1)\n",
    "\n",
    "# define model\n",
    "emb_model3 = tf.keras.Model(inputs=[lyric_input, artist_input], outputs=output3)\n",
    "\n",
    "# compile , train & evaluate the model\n",
    "emb_model3.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "emb_model3.fit([X_train_lyric, X_train_artist], y_train, epochs=10, validation_split=0.2, callbacks=[early_stopping])\n",
    "emb_loss3, emb_accuracy3 = emb_model3.evaluate([X_test_lyric, X_test_artist], y_test)\n",
    "print(\"Test Accuracy:\", emb_accuracy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained embeddings\n",
    "Using the gensim library, I will pretrain a Word2Vec model on the lyric data and train same set of models to compare with in-model embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# select lyrics & artist, convert to list, split into sentences & concatenate\n",
    "lyrics_list = music_df[\"Prsd_Lyrics\"].tolist()\n",
    "artist_list = music_df[\"Prsd_Artist\"].tolist()\n",
    "combined_texts = [lyrics + \" \" + artist for lyrics, artist in zip(lyrics_list, artist_list)]\n",
    "sentences_combined = [text.split() for text in combined_texts]\n",
    "\n",
    "# train the Word2Vec model\n",
    "w2v_pmodel = Word2Vec(sentences=sentences_combined, window=5, min_count=1, workers=4)\n",
    "\n",
    "# save model\n",
    "w2v_pmodel.save(\"models_p1/word2vec_model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vocab_size & embedding dimension\n",
    "embedding_dim = 100 \n",
    "w2v_lyric_vocab_size = len(w2v_pmodel.wv.key_to_index)\n",
    "w2v_artist_vocab_size = len(w2v_pmodel.wv.key_to_index)\n",
    "vocab_size1 = max(w2v_lyric_vocab_size, w2v_artist_vocab_size)\n",
    "\n",
    "# load pre-trained Word2vec embedding weights\n",
    "word2vec_model = gensim.models.Word2Vec.load(\"models_p1/word2vec_model\")\n",
    "w2v_embedding_matrix = np.zeros((vocab_size1, embedding_dim))\n",
    "\n",
    "# define input layers\n",
    "w2v_lyric_input = tf.keras.layers.Input(shape=(max_lyric_length,))\n",
    "w2v_artist_input = tf.keras.layers.Input(shape=(max_artist_length,))\n",
    "\n",
    "# define embedding layer\n",
    "w2v_lyric_embedding = tf.keras.layers.Embedding(input_dim=w2v_lyric_vocab_size, output_dim=embedding_dim, input_length=max_lyric_length, weights=[w2v_embedding_matrix])(w2v_lyric_input)\n",
    "w2v_lyric_flatten = tf.keras.layers.Flatten()(w2v_lyric_embedding)\n",
    "\n",
    "w2v_artist_embedding = tf.keras.layers.Embedding(input_dim=w2v_artist_vocab_size, output_dim=embedding_dim, input_length=max_artist_length, weights=[w2v_embedding_matrix])(w2v_artist_input)\n",
    "w2v_artist_flatten = tf.keras.layers.Flatten()(w2v_artist_embedding)\n",
    "\n",
    "w2v_concatenated = tf.keras.layers.concatenate([w2v_lyric_flatten, w2v_artist_flatten])\n",
    "\n",
    "# to reshape LSTM & RNN to 1 timestep\n",
    "w2v_reshaped = tf.keras.layers.Reshape((1, -1))(w2v_concatenated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM + Pre-trained Word2Vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "117/117 [==============================] - 121s 1s/step - loss: 1.3641 - accuracy: 0.5219 - val_loss: 1.1926 - val_accuracy: 0.6286\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 124s 1s/step - loss: 0.9086 - accuracy: 0.7331 - val_loss: 0.9766 - val_accuracy: 0.7051\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 122s 1s/step - loss: 0.3814 - accuracy: 0.8831 - val_loss: 1.0089 - val_accuracy: 0.7051\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 124s 1s/step - loss: 0.1201 - accuracy: 0.9838 - val_loss: 1.0559 - val_accuracy: 0.7094\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 116s 989ms/step - loss: 0.0404 - accuracy: 0.9987 - val_loss: 1.1098 - val_accuracy: 0.7061\n",
      "37/37 [==============================] - 6s 149ms/step - loss: 1.0501 - accuracy: 0.6830\n",
      "Test Accuracy: 0.6830318570137024\n"
     ]
    }
   ],
   "source": [
    "# LSTM layer\n",
    "lstm_layer2 = tf.keras.layers.LSTM(units=64)(w2v_reshaped)\n",
    "\n",
    "# output layer\n",
    "w2v_output1 = tf.keras.layers.Dense(len(label_dict), activation='softmax')(lstm_layer2)\n",
    "\n",
    "# define model\n",
    "w2v_model1 = tf.keras.Model(inputs=[w2v_lyric_input, w2v_artist_input], outputs=w2v_output1)\n",
    "\n",
    "# compile , train & evaluate the model\n",
    "w2v_model1.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "w2v_model1.fit([X_train_lyric, X_train_artist], y_train, epochs=10, validation_split=0.2, callbacks=[early_stopping])\n",
    "w2v_loss1, w2v_accuracy1 = w2v_model1.evaluate([X_test_lyric, X_test_artist], y_test)\n",
    "print(\"Test Accuracy:\", w2v_accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 4000)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 4000, 100)    4527200     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 25, 100)      4527200     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 400000)       0           ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 2500)         0           ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 402500)       0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 402500)    0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, 64)           103056640   ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 10)           650         ['lstm_4[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 112,111,690\n",
      "Trainable params: 112,111,690\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "w2v_model1.summary()\n",
    "w2v_model1.save(\"models_p11/emb/w2v_lstm.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN + Pre-trained Word2Vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "117/117 [==============================] - 58s 489ms/step - loss: 1.4589 - accuracy: 0.4034 - val_loss: 1.4087 - val_accuracy: 0.4295\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 55s 468ms/step - loss: 1.4166 - accuracy: 0.4086 - val_loss: 1.4020 - val_accuracy: 0.3746\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 57s 487ms/step - loss: 1.4127 - accuracy: 0.4061 - val_loss: 1.3961 - val_accuracy: 0.4295\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 54s 466ms/step - loss: 1.4148 - accuracy: 0.3973 - val_loss: 1.3974 - val_accuracy: 0.4295\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 54s 461ms/step - loss: 1.4082 - accuracy: 0.4094 - val_loss: 1.3978 - val_accuracy: 0.4295\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 54s 460ms/step - loss: 1.4109 - accuracy: 0.4005 - val_loss: 1.4013 - val_accuracy: 0.3746\n",
      "37/37 [==============================] - 3s 69ms/step - loss: 1.4528 - accuracy: 0.4040\n",
      "Test Accuracy: 0.403962105512619\n"
     ]
    }
   ],
   "source": [
    "# simple RNN layer\n",
    "rnn_layer2 = tf.keras.layers.SimpleRNN(units=64)(w2v_reshaped)\n",
    "\n",
    "# output layer\n",
    "w2v_output2 = tf.keras.layers.Dense(len(label_dict), activation='softmax')(rnn_layer2)\n",
    "\n",
    "# define model\n",
    "w2v_model2 = tf.keras.Model(inputs=[w2v_lyric_input, w2v_artist_input], outputs=w2v_output2)\n",
    "\n",
    "# compile , train & evaluate the model\n",
    "w2v_model2.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "w2v_model2.fit([X_train_lyric, X_train_artist], y_train, epochs=10, validation_split=0.2, callbacks=[early_stopping])\n",
    "w2v_loss2, w2v_accuracy2 = w2v_model2.evaluate([X_test_lyric, X_test_artist], y_test)\n",
    "print(\"Test Accuracy:\", w2v_accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense + Pre-trained Word2Vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "117/117 [==============================] - 45s 378ms/step - loss: 3.9287 - accuracy: 0.6655 - val_loss: 1.1304 - val_accuracy: 0.7137\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 42s 361ms/step - loss: 0.1430 - accuracy: 0.9596 - val_loss: 1.2328 - val_accuracy: 0.7137\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 43s 365ms/step - loss: 0.0243 - accuracy: 0.9989 - val_loss: 1.1602 - val_accuracy: 0.7374\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 42s 362ms/step - loss: 0.0099 - accuracy: 0.9997 - val_loss: 1.1839 - val_accuracy: 0.7395\n",
      "37/37 [==============================] - 2s 65ms/step - loss: 1.2069 - accuracy: 0.6779\n",
      "Test Accuracy: 0.6778638958930969\n"
     ]
    }
   ],
   "source": [
    "# dense layer\n",
    "w2v_flattened = tf.keras.layers.Flatten()(w2v_concatenated) # to convert multi-D data into 1D tensor\n",
    "dense2 = tf.keras.layers.Dense(units=64)(w2v_flattened) \n",
    "\n",
    "# output layer\n",
    "w2v_output3 = tf.keras.layers.Dense(len(label_dict), activation='softmax')(dense2)\n",
    "\n",
    "# pre_trained embedding model\n",
    "w2v_model3 = tf.keras.Model(inputs=[w2v_lyric_input, w2v_artist_input], outputs=w2v_output3)\n",
    "\n",
    "# compile , train & evaluate the model\n",
    "w2v_model3.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "w2v_model3.fit([X_train_lyric, X_train_artist], y_train, epochs=10, validation_split=0.2, callbacks=[early_stopping])\n",
    "w2v_loss3, w2v_accuracy3 = w2v_model3.evaluate([X_test_lyric, X_test_artist], y_test)\n",
    "print(\"Test Accuracy:\", w2v_accuracy3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional layers\n",
    "Experimenting with convolutional layers-only models and mixing in LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "117/117 [==============================] - 39s 325ms/step - loss: 1.6879 - accuracy: 0.4883 - val_loss: 1.3300 - val_accuracy: 0.5221\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 37s 315ms/step - loss: 1.3413 - accuracy: 0.5101 - val_loss: 1.3519 - val_accuracy: 0.5167\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 35s 300ms/step - loss: 1.2911 - accuracy: 0.5160 - val_loss: 1.3599 - val_accuracy: 0.4962\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 35s 301ms/step - loss: 1.2416 - accuracy: 0.5308 - val_loss: 1.4163 - val_accuracy: 0.4962\n",
      "37/37 [==============================] - 3s 67ms/step - loss: 1.3962 - accuracy: 0.4944\n",
      "Test Accuracy: 0.49440136551856995\n"
     ]
    }
   ],
   "source": [
    "# define CNN model\n",
    "cnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=5, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Conv1D(filters=128, kernel_size=7, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=len(label_dict), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# compile model\n",
    "cnn_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train & evaluate model\n",
    "cnn_model.fit(X_train, y_train, epochs=10, validation_split=0.2, callbacks=[early_stopping])\n",
    "loss, accuracy = cnn_model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "117/117 [==============================] - 144s 1s/step - loss: 1.4198 - accuracy: 0.4126 - val_loss: 1.3720 - val_accuracy: 0.4263\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 188s 2s/step - loss: 1.3774 - accuracy: 0.4236 - val_loss: 1.3801 - val_accuracy: 0.4306\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 180s 2s/step - loss: 1.3708 - accuracy: 0.4271 - val_loss: 1.3648 - val_accuracy: 0.4467\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 161s 1s/step - loss: 1.3699 - accuracy: 0.4336 - val_loss: 1.3644 - val_accuracy: 0.4489\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 166s 1s/step - loss: 1.3655 - accuracy: 0.4172 - val_loss: 1.3654 - val_accuracy: 0.4284\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 182s 2s/step - loss: 1.3621 - accuracy: 0.4293 - val_loss: 1.3667 - val_accuracy: 0.4155\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 179s 2s/step - loss: 1.3615 - accuracy: 0.4328 - val_loss: 1.3737 - val_accuracy: 0.4177\n",
      "37/37 [==============================] - 16s 439ms/step - loss: 1.3986 - accuracy: 0.4272\n",
      "Test Accuracy: 0.42721790075302124\n"
     ]
    }
   ],
   "source": [
    "# define CNN + LSTM model\n",
    "cnnlstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Reshape((-1, 32)), # reshape for LSTM input\n",
    "    tf.keras.layers.LSTM(units=64, return_sequences=False),\n",
    "    tf.keras.layers.Dense(units=len(label_dict), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# compile model\n",
    "cnnlstm_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train & evalutate model\n",
    "cnnlstm_model.fit(X_train, y_train, epochs=10, validation_split=0.2, callbacks=[early_stopping])\n",
    "loss1, accuracy1 = cnnlstm_model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

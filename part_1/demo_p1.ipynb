{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Lyric genre prediction task\n",
    "This notebook contains the top 2 models selected based on their performance during training and validation for 2 input features = Model L and Model H."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on original test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# import test dataset\n",
    "music_test = pd.read_csv(\"data/test.csv\", index_col=False, sep=\",\", quotechar='\"')\n",
    "\n",
    "# function to lowercase, remove punctuation & stopwords\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return filtered_text\n",
    "\n",
    "# preprocess lyrics\n",
    "music_test[\"Prsd_Lyrics\"] = music_test[\"Lyrics\"].apply(preprocess_text)\n",
    "\n",
    "# preprocess artist\n",
    "music_test[\"Prsd_Artist\"] = music_test[\"Artist\"].apply(preprocess_text)\n",
    "\n",
    "# extract labels & convert to one-hot encoded vectors\n",
    "labels = music_test[\"Genre\"]\n",
    "label_dict = {label: i for i, label in enumerate(labels.unique())}\n",
    "labels_encoded = labels.map(label_dict)\n",
    "labels_categorical = tf.keras.utils.to_categorical(labels_encoded)\n",
    "\n",
    "# tokenize & pad lyrics and artist\n",
    "tokenizer_lyrics = Tokenizer(char_level=True)\n",
    "tokenizer_artist = Tokenizer()\n",
    "tokenizer_lyrics.fit_on_texts(music_test['Prsd_Lyrics'])\n",
    "sequences_lyrics = tokenizer_lyrics.texts_to_sequences(music_test['Prsd_Lyrics'])\n",
    "tokenizer_artist.fit_on_texts(music_test['Prsd_Artist'])\n",
    "sequences_artist = tokenizer_artist.texts_to_sequences(music_test['Prsd_Artist'])\n",
    "\n",
    "max_lyric_length = 4000 # chosen based on distribution above, excluding extreme values\n",
    "max_artist_length = 25\n",
    "\n",
    "# filter out OOV tokens from input features\n",
    "filtered_sequences_lyrics = [[token for token in seq if token in tokenizer_lyrics.word_index] for seq in sequences_lyrics]\n",
    "filtered_sequences_artist = [[token for token in seq if token in tokenizer_artist.word_index] for seq in sequences_artist]\n",
    "\n",
    "# Pad filtered sequences\n",
    "X_lyrics_filtered = pad_sequences(filtered_sequences_lyrics, maxlen=max_lyric_length)\n",
    "X_artist_filtered = pad_sequences(filtered_sequences_artist, maxlen=max_artist_length)\n",
    "\n",
    "# ensure max length is respected\n",
    "X_test = np.concatenate((X_lyrics_filtered, X_artist_filtered), axis=1)\n",
    "y_test = labels_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate top models from training & validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate top models\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # calculate precision, recall, and F1-score\n",
    "    precision_metric = tf.keras.metrics.Precision()\n",
    "    recall_metric = tf.keras.metrics.Recall()\n",
    "\n",
    "    # update the metrics\n",
    "    precision_metric.update_state(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "    recall_metric.update_state(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "\n",
    "    # get the metric values\n",
    "    precision_value = precision_metric.result().numpy()\n",
    "    recall_value = recall_metric.result().numpy()\n",
    "\n",
    "    return loss, accuracy, precision_value, recall_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model H - In-training embeddeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if gdown not installed\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download model from drive\n",
    "emb_url = 'https://drive.google.com/file/d/1K0TRAstgjqjvwsEpUnCPV_tdvkfbo5-x/uc?usp=drive_link'\n",
    "emb = 'emb_dense.keras'\n",
    "gdown.download(emb_url, emb, quiet=False)\n",
    "\n",
    "# load model\n",
    "emb_model = tf.keras.models.load_model(\"models/emb/emb_dense.keras\")\n",
    "\n",
    "# evaluate model\n",
    "emb_loss, emb_accuracy, emb_precision_value, emb_recall_value = evaluate_model(emb_model, [X_lyrics_filtered, X_artist_filtered], y_test)\n",
    "\n",
    "print(\"Loss:\", emb_loss)\n",
    "print(\"Accuracy:\", emb_accuracy)\n",
    "print(\"Precision:\", emb_precision_value)\n",
    "print(\"Recall:\", emb_recall_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model L - Pre-trained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download model from drive\n",
    "w2v_url = 'https://drive.google.com/file/d/1f42AjyMPQNISW1opPp_BSX8TeZnu5XXo/uc?usp=drive_link'\n",
    "w2v = 'w2v_lstm.keras'\n",
    "gdown.download(w2v_url, w2v, quiet=False)\n",
    "\n",
    "# load model\n",
    "w2v_model = tf.keras.models.load_model(w2v)\n",
    "\n",
    "# evaluate model\n",
    "w2v_loss, w2v_accuracy, w2v_precision_value, w2v_recall_value = evaluate_model(w2v_model, [X_lyrics_filtered, X_artist_filtered], y_test)\n",
    "\n",
    "print(\"Loss:\", w2v_loss)\n",
    "print(\"Accuracy:\", w2v_accuracy)\n",
    "print(\"Precision:\", w2v_precision_value)\n",
    "print(\"Recall:\", w2v_recall_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on downsampled test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose 2% sample for training & validation and export\n",
    "newlen = int(len(music_test) * 0.02)\n",
    "sample_test = music_test.sample(n=newlen, random_state=53)\n",
    "\n",
    "# preprocess lyrics & artist\n",
    "sample_test[\"Prsd_Lyrics\"] = sample_test[\"Lyrics\"].apply(preprocess_text)\n",
    "sample_test[\"Prsd_Artist\"] = sample_test[\"Artist\"].apply(preprocess_text)\n",
    "\n",
    "# extract labels & convert to one-hot encoded vectors\n",
    "labels_b = sample_test[\"Genre\"]\n",
    "label_dict_b = {label_b: i for i, label_b in enumerate(labels_b.unique())}\n",
    "labels_encoded_b = labels_b.map(label_dict_b)\n",
    "labels_categorical_b = tf.keras.utils.to_categorical(labels_encoded_b)\n",
    "\n",
    "# tokenize & pad lyrics and artist\n",
    "tokenizer_lyrics_b = Tokenizer(char_level=True)\n",
    "tokenizer_artist_b = Tokenizer()\n",
    "tokenizer_lyrics_b.fit_on_texts(sample_test['Prsd_Lyrics'])\n",
    "sequences_lyrics_b = tokenizer_lyrics.texts_to_sequences(sample_test['Prsd_Lyrics'])\n",
    "tokenizer_artist_b.fit_on_texts(sample_test['Prsd_Artist'])\n",
    "sequences_artist_b = tokenizer_artist.texts_to_sequences(sample_test['Prsd_Artist'])\n",
    "\n",
    "# filter out OOV tokens from input features\n",
    "filtered_sequences_lyrics_b = [[token for token in seq if token in tokenizer_lyrics_b.word_index] for seq in sequences_lyrics_b]\n",
    "filtered_sequences_artist_b = [[token for token in seq if token in tokenizer_artist_b.word_index] for seq in sequences_artist_b]\n",
    "\n",
    "# Pad filtered sequences\n",
    "X_lyrics_filtered_b = pad_sequences(filtered_sequences_lyrics_b, maxlen=max_lyric_length)\n",
    "X_artist_filtered_b = pad_sequences(filtered_sequences_artist_b, maxlen=max_artist_length)\n",
    "\n",
    "# ensure max length is respected\n",
    "X_test_b = np.concatenate((X_lyrics_filtered_b, X_artist_filtered_b), axis=1)\n",
    "y_test_b = labels_categorical_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate top models from training & validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model H - In-training embeddeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "emb_loss_b, emb_accuracy_b, emb_precision_value_b, emb_recall_value_b = evaluate_model(emb_model, [X_lyrics_filtered_b, X_artist_filtered_b], y_test_b)\n",
    "\n",
    "print(\"Loss:\", emb_loss_b)\n",
    "print(\"Accuracy:\", emb_accuracy_b)\n",
    "print(\"Precision:\", emb_precision_value_b)\n",
    "print(\"Recall:\", emb_recall_value_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model L - Pre-trained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "w2v_loss_b, w2v_accuracy_b, w2v_precision_value_b, w2v_recall_value_b = evaluate_model(w2v_model, [X_lyrics_filtered_b, X_artist_filtered_b], y_test_b)\n",
    "\n",
    "print(\"Loss:\", w2v_loss_b)\n",
    "print(\"Accuracy:\", w2v_accuracy_b)\n",
    "print(\"Precision:\", w2v_precision_value_b)\n",
    "print(\"Recall:\", w2v_recall_value_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
